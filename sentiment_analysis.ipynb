{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 10 Assignment \n",
    "\n",
    "Lyn Nguyen Nov. 2022\n",
    "\n",
    "Design a sentiment analysis classifier using the **Sentiment 140** corpus and **NLTK**. Test the classifier using content from Twitter and Reddit. Describe any limitations of your sentiment analyzer. Turn in Python code as a Jupyter for the classifier.\n",
    "\n",
    "\n",
    "http://help.sentiment140.com/for-students\n",
    "\n",
    "- data: trainingandtestdata folder \n",
    "\t\n",
    "http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\n",
    "\n",
    "- how to put together a sentiment analysis classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFIER\n",
    "We get a list of features (words) and their frequencies next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIER\n",
    "import nltk\n",
    "\n",
    "def get_words_in_tweets(tweets):  \n",
    "    \"\"\"smush all the words in the tweets into a single list\"\"\"\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "      all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    \"\"\" Outputs dictionary, although \n",
    "        no frequency count shows up (wordlist)\"\"\"\n",
    "    wordlist = nltk.FreqDist(wordlist)  # FreqDist({'word1': 3, 'word2': 1, etc.}) ordered from most freq to least\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features \n",
    "\n",
    "word_features = get_word_features(get_words_in_tweets(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        \"\"\"word_features is predefined above as list of \n",
    "           3+ letter tokens from all tweets combined\"\"\"\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL PROJECT TRIAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP WORDS - from topic_modeling_11\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.',  ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}','year', # remove it if you need punctuation\n",
    "'#', '://', '/', 'www', '-', 'com', '=', '...', 'org', 'https', '@', '&', \"'\", '\"', 'msnbc', 'foxnews', 'npr', 'nytimes', 'cnn', 'usedgov']) # added for this assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn df['tweet'] into token variables \n",
    "\n",
    "def tokenize_column(df): \n",
    "    '''From hw 8'''\n",
    "    # input data\n",
    "    # stem = pd.DataFrame(df)\n",
    "\n",
    "    # iterate each col's row, use a list to add it back to the dataframe\n",
    "    tokenized_list = []\n",
    "    tLenList = []\n",
    "    msgLen = []\n",
    "    for ind in df.index: \n",
    "        msg = df['text'][ind]           #tweet--> text\n",
    "        # tokens = word_tokenize(msg)\n",
    "        tokens = TweetTokenizer().tokenize(msg) # https://stackoverflow.com/questions/34714162/preventing-splitting-at-apostrophies-when-tokenizing-words-using-nltk\n",
    "        # tknzr = TweetTokenizer()\n",
    "        # tknzr.tokenize(\"@Kenichan I haven't dived many times for the ball. Man\")\n",
    "\n",
    "        # tokenized_list.append(tokens) <-- uncomment for non-stopwords token\n",
    "        # tLenList.append(len(tokens))\n",
    "        # msgLen.append(len(msg))\n",
    "\n",
    "\n",
    "        # remove stopwords \n",
    "        ts = [i.lower() for i in tokens if i.lower not in stop_words]\n",
    "        tokenized_list.append(ts)\n",
    "        tLenList.append(len(ts))\n",
    "        msgLen.append(len(ts))\n",
    "        \n",
    "\n",
    "    df['wordTokenize'] = tokenized_list\n",
    "    df['tokenLength'] = tLenList\n",
    "    df['msgLen'] = msgLen\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/master_annotated.csv\"\n",
    "fp = pd.read_csv(input_path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_annotation_confidence</th>\n",
       "      <th>ego_involvement_key</th>\n",
       "      <th>ego_involvement_label</th>\n",
       "      <th>ego_involvement_annotation_confidence</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>466</td>\n",
       "      <td>usedgov</td>\n",
       "      <td>@usedgov why are my student loans not transfer...</td>\n",
       "      <td>1.599892e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 22:24:29 +0000 2022</td>\n",
       "      <td>7.925171e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>0.79</td>\n",
       "      <td>[@usedgov, why, are, my, student, loans, not, ...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>467</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Just another way of screwing the taxp...</td>\n",
       "      <td>1.599894e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 22:32:26 +0000 2022</td>\n",
       "      <td>1.518825e+18</td>\n",
       "      <td>1.599351e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>0.42</td>\n",
       "      <td>3</td>\n",
       "      <td>cannot judge importance</td>\n",
       "      <td>0.40</td>\n",
       "      <td>[@foxnews, just, another, way, of, screwing, t...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>468</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews The Democrats don√¢¬Ä¬ôt seem to be tryi...</td>\n",
       "      <td>1.599904e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 23:09:08 +0000 2022</td>\n",
       "      <td>1.586128e+18</td>\n",
       "      <td>1.599901e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>cannot judge support</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>0.69</td>\n",
       "      <td>[@foxnews, the, democrats, don√¢, ¬Ä, ¬ô, t, seem...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  experiment_id experiment_group  \\\n",
       "465         465            466          usedgov   \n",
       "466         466            467          foxnews   \n",
       "467         467            468          foxnews   \n",
       "\n",
       "                                                  text      tweet_id  \\\n",
       "465  @usedgov why are my student loans not transfer...  1.599892e+18   \n",
       "466  @FoxNews Just another way of screwing the taxp...  1.599894e+18   \n",
       "467  @FoxNews The Democrats don√¢¬Ä¬ôt seem to be tryi...  1.599904e+18   \n",
       "\n",
       "     tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "465            0         0  Mon Dec 05 22:24:29 +0000 2022  7.925171e+17   \n",
       "466            0         0  Mon Dec 05 22:32:26 +0000 2022  1.518825e+18   \n",
       "467            0         0  Mon Dec 05 23:09:08 +0000 2022  1.586128e+18   \n",
       "\n",
       "     in_reply_to_status_id  ...  text_word_count opinion_key  \\\n",
       "465                    NaN  ...               33           0   \n",
       "466           1.599351e+18  ...               45           2   \n",
       "467           1.599901e+18  ...               35           3   \n",
       "\n",
       "                        opinion_label opinion_annotation_confidence  \\\n",
       "465     FOR student loan forgiveness                           0.95   \n",
       "466  AGAINST student loan forgiveness                          0.42   \n",
       "467              cannot judge support                          0.66   \n",
       "\n",
       "    ego_involvement_key    ego_involvement_label  \\\n",
       "465                   1       Somewhat important   \n",
       "466                   3  cannot judge importance   \n",
       "467                   0           Very important   \n",
       "\n",
       "    ego_involvement_annotation_confidence  \\\n",
       "465                                  0.79   \n",
       "466                                  0.40   \n",
       "467                                  0.69   \n",
       "\n",
       "                                          wordTokenize tokenLength msgLen  \n",
       "465  [@usedgov, why, are, my, student, loans, not, ...          39     39  \n",
       "466  [@foxnews, just, another, way, of, screwing, t...          44     44  \n",
       "467  [@foxnews, the, democrats, don√¢, ¬Ä, ¬ô, t, seem...          40     40  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a tokenized list from Twitter text\n",
    "df1 = tokenize_column(fp)\n",
    "df1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEUTRAL support                     193\n",
       "AGAINST student loan forgiveness    136\n",
       "FOR student loan forgiveness        120\n",
       "cannot judge support                 19\n",
       "Name: opinion_label, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how balanced the data is. total count of negative, neutral, and positive sentiment. \n",
    "df1['opinion_label'].value_counts() # sentiment --> opinion_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['wordTokenize', 'opinion_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>opinion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>[@foxnews, just, another, way, of, screwing, t...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>[@foxnews, the, democrats, don√¢, ¬Ä, ¬ô, t, seem...</td>\n",
       "      <td>cannot judge support</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          wordTokenize  \\\n",
       "466  [@foxnews, just, another, way, of, screwing, t...   \n",
       "467  [@foxnews, the, democrats, don√¢, ¬Ä, ¬ô, t, seem...   \n",
       "\n",
       "                        opinion_label  \n",
       "466  AGAINST student loan forgiveness  \n",
       "467              cannot judge support  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail(2)\n",
    "# fp_data = fb[['wordTokenize', 'opinion_label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1033)\n",
    "training_count = len(df1)*.8\n",
    "# training = df1.sample(n = training_count)\n",
    "\n",
    "# https://www.geeksforgeeks.org/how-to-do-train-test-split-using-sklearn-in-python/\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1.get('wordTokenize')\n",
    "y = df1.get('opinion_label')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1002, test_size = .2, shuffle = False)\n",
    "\n",
    "training_data = pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def records(df): \n",
    "    # https://stackoverflow.com/questions/9758450/pandas-convert-dataframe-to-array-of-tuples\n",
    "    return df.to_records(index=False).tolist()\n",
    "training_data = records(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input need columns wordTokenize, sentiment \n",
    "word_features = get_word_features(get_words_in_tweets(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        \"\"\"word_features is predefined above as list of \n",
    "           3+ letter tokens from all tweets combined\"\"\"\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# apply features to classifier with our feature_extract function \n",
    "# it outputs a list of tuple, each tuple holds the \"feature dictionary\"\n",
    "training_set = nltk.classify.apply_features(extract_features, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our classifier using our training data set\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGAINST student loan forgiveness'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it out \n",
    "tweet = \"@FoxNews He\\'s having issues isn't he. He can't pass a ban on pew pews, he can't do student loan forgiveness (kind of intentional btw,) he can't pass gas because his heads in the way of natural progression in his bum. He just can't catch a break man. üò™\"\n",
    "\n",
    "classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classifier to Student Loan Twitter Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student_data = pd.read_csv('data/master_annotated.csv')\n",
    "# student_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data \n",
    "test_data = pd.concat(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = student_data[['text', 'opinion_label']]\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/skpws_rj3nd2_9dzb8zqs6900000gn/T/ipykernel_83410/1865138473.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data[\"predicted_sentiment\"] = class_list\n"
     ]
    }
   ],
   "source": [
    "class_list = []\n",
    "for row in test_data.index:\n",
    "    msg = test_data['text'][row]\n",
    "    msg_split = msg.split()\n",
    "    result = classifier.classify(extract_features(msg_split))\n",
    "    class_list.append(result)\n",
    "test_data[\"predicted_sentiment\"] = class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MSNBC @MaddowBlog I feel sorry for the sucker...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@MSNBC @MaddowBlog Setting up a 2024 elections...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...   \n",
       "1  @MSNBC @MaddowBlog I feel sorry for the sucker...   \n",
       "2  @MSNBC @MaddowBlog Setting up a 2024 elections...   \n",
       "\n",
       "                      opinion_label               predicted_sentiment match  \n",
       "0  AGAINST student loan forgiveness  AGAINST student loan forgiveness   yes  \n",
       "1                   NEUTRAL support                   NEUTRAL support   yes  \n",
       "2  AGAINST student loan forgiveness  AGAINST student loan forgiveness   yes  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/skpws_rj3nd2_9dzb8zqs6900000gn/T/ipykernel_83410/3574436141.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['match'] = np.select(conditions, values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MSNBC @MaddowBlog I feel sorry for the sucker...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@MSNBC @MaddowBlog Setting up a 2024 elections...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@MSNBC @MaddowBlog If you can't pay off studen...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@MSNBC @MaddowBlog The simple defense is why s...</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>@FoxNews I don't need any bias media to tell m...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>@FoxNews He still trying to get college studen...</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>@usedgov why are my student loans not transfer...</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>@FoxNews Just another way of screwing the taxp...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>@FoxNews The Democrats don‚Äôt seem to be trying...</td>\n",
       "      <td>cannot judge support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    @MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...   \n",
       "1    @MSNBC @MaddowBlog I feel sorry for the sucker...   \n",
       "2    @MSNBC @MaddowBlog Setting up a 2024 elections...   \n",
       "3    @MSNBC @MaddowBlog If you can't pay off studen...   \n",
       "4    @MSNBC @MaddowBlog The simple defense is why s...   \n",
       "..                                                 ...   \n",
       "463  @FoxNews I don't need any bias media to tell m...   \n",
       "464  @FoxNews He still trying to get college studen...   \n",
       "465  @usedgov why are my student loans not transfer...   \n",
       "466  @FoxNews Just another way of screwing the taxp...   \n",
       "467  @FoxNews The Democrats don‚Äôt seem to be trying...   \n",
       "\n",
       "                        opinion_label               predicted_sentiment match  \n",
       "0    AGAINST student loan forgiveness  AGAINST student loan forgiveness   yes  \n",
       "1                     NEUTRAL support                   NEUTRAL support   yes  \n",
       "2    AGAINST student loan forgiveness  AGAINST student loan forgiveness   yes  \n",
       "3                     NEUTRAL support                   NEUTRAL support   yes  \n",
       "4       FOR student loan forgiveness                    NEUTRAL support    no  \n",
       "..                                ...                               ...   ...  \n",
       "463  AGAINST student loan forgiveness                   NEUTRAL support    no  \n",
       "464     FOR student loan forgiveness                    NEUTRAL support    no  \n",
       "465     FOR student loan forgiveness   AGAINST student loan forgiveness    no  \n",
       "466  AGAINST student loan forgiveness                   NEUTRAL support    no  \n",
       "467              cannot judge support                   NEUTRAL support    no  \n",
       "\n",
       "[468 rows x 4 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column to show if predicted_sentiment is the same as sentiment\n",
    "conditions = [(test_data['opinion_label']==test_data['predicted_sentiment']),\n",
    "(test_data['opinion_label'] != test_data['predicted_sentiment'])]\n",
    "values = ['yes', 'no']\n",
    "test_data['match'] = np.select(conditions, values)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    342\n",
       "no     126\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count up now many matches\n",
    "test_data['match'].value_counts() # 342/468 = 73% correct  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY RATE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDIT AFTER MODEL COMPLETED\n",
    "\n",
    "There are 96 matches between `predicted_sentiment` and `sentiment` out of 163 test data points. That is 59% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is accurate more than 1/2 of the time. Given its constraints, 59% is acceptable. We believe that if future work address the limitations of this model, the result will improve. Below is a list of the model's limitation: \n",
    "- not able to use emoticons \n",
    "- not recognizing @username as an entity/subject\n",
    "- no treatment for commas and periods\n",
    "- treat lower/upper cases differenlty\n",
    "- special characters and hashtags are still in test data, unaddressed\n",
    "- needed to remove stop words from the training model\n",
    "- A larger training data set might yield better result. We only used 0.125% of the provided Sentiment 140 dataset (2K out of 1.6 million rows). \n",
    "\n",
    "Finally, the pre-labeled test data could not be neatly categorize. For example, when we sense \"hope\" in the text, we would label it as positive, even though there are negative sentiment that prefaces the hope/resolution. \n",
    "ex: \n",
    ">@POTUS since your student loan forgiveness move is not going to pass muster with the courts, why not do something legitimate and fair. Lock all student loans at 1% interest for all existing and future loans. #StudentLoans2022 #loanforgiveness #studentloans #college\n",
    "\n",
    "The manual we gave this tweet was 'positive' but our model categorizes it as 'negative'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_values = test_data[test_data['tweet'].str.contains('@POTUS since your student loan forgiveness move is not going to pass muster with the courts')]\n",
    "contain_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f77f65dbbcf4e8b4a8cd70b43e47feb633efa338cacdb2d15ff3e58ba7027a78"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('socialmedia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
