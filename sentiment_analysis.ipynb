{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 10 Assignment \n",
    "\n",
    "Lyn Nguyen Nov. 2022\n",
    "\n",
    "Design a sentiment analysis classifier using the **Sentiment 140** corpus and **NLTK**. Test the classifier using content from Twitter and Reddit. Describe any limitations of your sentiment analyzer. Turn in Python code as a Jupyter for the classifier.\n",
    "\n",
    "\n",
    "http://help.sentiment140.com/for-students\n",
    "\n",
    "- data: trainingandtestdata folder \n",
    "\t\n",
    "http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\n",
    "\n",
    "- how to put together a sentiment analysis classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['love', 'this', 'car'], 'positive'), (['this', 'view', 'amazing'], 'positive'), (['feel', 'great', 'this', 'morning'], 'positive'), (['excited', 'about', 'the', 'concert'], 'positive'), (['best', 'friend'], 'positive'), (['not', 'like', 'this', 'car'], 'negative'), (['this', 'view', 'horrible'], 'negative'), (['feel', 'tired', 'this', 'morning'], 'negative'), (['not', 'looking', 'forward', 'the', 'concert'], 'negative'), (['enemy'], 'negative'), (['@kenichan', 'dived', 'many', 'times', 'for', 'the', 'ball.', 'applepie', 'man.'], 'negative')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['feel', 'happy', 'this', 'morning'], 'positive'),\n",
       " (['larry', 'friend'], 'positive'),\n",
       " (['not', 'like', 'that', 'man'], 'negative'),\n",
       " (['house', 'not', 'great'], 'negative'),\n",
       " (['your', 'song', 'annoying'], 'negative')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run what's in laurentluce.com \n",
    "pos_tweets = [('I love this car', 'positive'),\n",
    "              ('This view is amazing', 'positive'),\n",
    "              ('I feel great this morning', 'positive'),\n",
    "              ('I am so excited about the concert', 'positive'),\n",
    "              ('He is my best friend', 'positive')]\n",
    "neg_tweets = [('I do not like this car', 'negative'),\n",
    "              ('This view is horrible', 'negative'),\n",
    "              ('I feel tired this morning', 'negative'),\n",
    "              ('I am not looking forward to the concert', 'negative'),\n",
    "              ('He is my enemy', 'negative'),\n",
    "              ('@Kenichan I dived many times for the ball. applepie Man.', 'negative')] # added\n",
    "\n",
    "tweets = []\n",
    "\n",
    "for (words, sentiment) in pos_tweets + neg_tweets:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3] #throw out words with 1 or 2 characters\n",
    "    tweets.append((words_filtered, sentiment))\n",
    "\n",
    "print(tweets)\n",
    "\n",
    "test_tweets = [\n",
    "    (['feel', 'happy', 'this', 'morning'], 'positive'),\n",
    "    (['larry', 'friend'], 'positive'),\n",
    "    (['not', 'like', 'that', 'man'], 'negative'),\n",
    "    (['house', 'not', 'great'], 'negative'),\n",
    "    (['your', 'song', 'annoying'], 'negative')]\n",
    "\n",
    "test_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFIER\n",
    "We get a list of features (words) and their frequencies next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIER\n",
    "import nltk\n",
    "\n",
    "def get_words_in_tweets(tweets):  \n",
    "    \"\"\"smush all the words in the tweets into a single list\"\"\"\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "      all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    \"\"\" Outputs dictionary, although \n",
    "        no frequency count shows up (wordlist)\"\"\"\n",
    "    wordlist = nltk.FreqDist(wordlist)  # FreqDist({'word1': 3, 'word2': 1, etc.}) ordered from most freq to least\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features \n",
    "\n",
    "word_features = get_word_features(get_words_in_tweets(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['this', 'view', 'amazing'], 'positive'),\n",
       " (['feel', 'great', 'this', 'morning'], 'positive')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[1:3]\n",
    "# type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'this': 6, 'the': 3, 'car': 2, 'view': 2, 'feel': 2, 'morning': 2, 'concert': 2, 'not': 2, 'love': 1, 'amazing': 1, ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(get_words_in_tweets(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['love', 'this', 'car', 'view', 'amazing', 'feel', 'great', 'morning', 'excited', 'about', 'the', 'concert', 'best', 'friend', 'not', 'like', 'horrible', 'tired', 'looking', 'forward', 'enemy', '@kenichan', 'dived', 'many', 'times', 'for', 'ball.', 'applepie', 'man.'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        \"\"\"word_features is predefined above as list of \n",
    "           3+ letter tokens from all tweets combined\"\"\"\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(love)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(car)': True,\n",
       " 'contains(view)': False,\n",
       " 'contains(amazing)': False,\n",
       " 'contains(feel)': False,\n",
       " 'contains(great)': False,\n",
       " 'contains(morning)': False,\n",
       " 'contains(excited)': False,\n",
       " 'contains(about)': False,\n",
       " 'contains(the)': False,\n",
       " 'contains(concert)': False,\n",
       " 'contains(best)': False,\n",
       " 'contains(friend)': False,\n",
       " 'contains(not)': False,\n",
       " 'contains(like)': False,\n",
       " 'contains(horrible)': False,\n",
       " 'contains(tired)': False,\n",
       " 'contains(looking)': False,\n",
       " 'contains(forward)': False,\n",
       " 'contains(enemy)': False,\n",
       " 'contains(@kenichan)': False,\n",
       " 'contains(dived)': False,\n",
       " 'contains(many)': False,\n",
       " 'contains(times)': False,\n",
       " 'contains(for)': False,\n",
       " 'contains(ball.)': False,\n",
       " 'contains(applepie)': False,\n",
       " 'contains(man.)': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example \n",
    "extract_features(['love', 'this', 'car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'contains(love)': True, 'contains(this)': True, 'contains(car)': True, 'contains(view)': False, 'contains(amazing)': False, 'contains(feel)': False, 'contains(great)': False, 'contains(morning)': False, 'contains(excited)': False, 'contains(about)': False, 'contains(the)': False, 'contains(concert)': False, 'contains(best)': False, 'contains(friend)': False, 'contains(not)': False, 'contains(like)': False, 'contains(horrible)': False, 'contains(tired)': False, 'contains(looking)': False, 'contains(forward)': False, 'contains(enemy)': False, 'contains(@kenichan)': False, 'contains(dived)': False, 'contains(many)': False, 'contains(times)': False, 'contains(for)': False, 'contains(ball.)': False, 'contains(applepie)': False, 'contains(man.)': False}, 'positive'), ({'contains(love)': False, 'contains(this)': True, 'contains(car)': False, 'contains(view)': True, 'contains(amazing)': True, 'contains(feel)': False, 'contains(great)': False, 'contains(morning)': False, 'contains(excited)': False, 'contains(about)': False, 'contains(the)': False, 'contains(concert)': False, 'contains(best)': False, 'contains(friend)': False, 'contains(not)': False, 'contains(like)': False, 'contains(horrible)': False, 'contains(tired)': False, 'contains(looking)': False, 'contains(forward)': False, 'contains(enemy)': False, 'contains(@kenichan)': False, 'contains(dived)': False, 'contains(many)': False, 'contains(times)': False, 'contains(for)': False, 'contains(ball.)': False, 'contains(applepie)': False, 'contains(man.)': False}, 'positive'), ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply features to classifier with our feature_extract function \n",
    "# it outputs a list of tuple, each tuple holds the \"feature dictionary\"\n",
    "training_set = nltk.classify.apply_features(extract_features, tweets)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our classifier using our training data set\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive output because of word \"friend\"\n",
    "tweet = 'Larry is my friend'\n",
    "classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply\n",
    "\n",
    "Now that we got the tutorial to work, let's call in Sentiment 140 data. These are their column names: \n",
    "\n",
    "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "1 - the id of the tweet (2087)\n",
    "\n",
    "2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "4 - the user that tweeted (robotickilldozr)\n",
    "\n",
    "5 - the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL PROJECT TRIAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL PROJECT (FB)\n",
    "input_path = \"data/master_annotated.csv\"\n",
    "fp = pd.read_csv(input_path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'experiment_id', 'experiment_group', 'text', 'tweet_id',\n",
       "       'tweet_likes', 'retweets', 'tweet_created_at', 'user_id',\n",
       "       'in_reply_to_status_id', 'in_reply_to_user_id',\n",
       "       'in_reply_to_screen_name', 'dow', 'month_day', 'time', 'yr', 'ymd',\n",
       "       'tweet_id_char', 'created_at', 'description', 'location',\n",
       "       'followers_count', 'screen_name', 'statuses_count', 'favourites_count',\n",
       "       'verified', 'user_id_char', 'text_length', 'text_word_count',\n",
       "       'opinion_key', 'opinion_label', 'opinion_annotation_confidence',\n",
       "       'ego_involvement_key', 'ego_involvement_label',\n",
       "       'ego_involvement_annotation_confidence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_annotation_confidence</th>\n",
       "      <th>ego_involvement_key</th>\n",
       "      <th>ego_involvement_label</th>\n",
       "      <th>ego_involvement_annotation_confidence</th>\n",
       "      <th>algorithm_opinion</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>@MSNBC @MaddowBlog √¢¬Ä¬úSimpleton√¢¬Ä¬ôs defense√¢¬Ä¬ù...</td>\n",
       "      <td>1.596988e+18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Nov 27 22:01:59 +0000 2022</td>\n",
       "      <td>1.518750e+18</td>\n",
       "      <td>1.596987e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>0.95</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>[@MSNBC, @MaddowBlog, √¢, ¬Ä, ¬ú, Simpleton√¢, ¬Ä, ...</td>\n",
       "      <td>47</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>@MSNBC @MaddowBlog I feel sorry for the sucker...</td>\n",
       "      <td>1.596993e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Nov 27 22:22:27 +0000 2022</td>\n",
       "      <td>3.202809e+09</td>\n",
       "      <td>1.596987e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3</td>\n",
       "      <td>cannot judge importance</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>[@MSNBC, @MaddowBlog, I, feel, sorry, for, the...</td>\n",
       "      <td>21</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>@MSNBC @MaddowBlog Setting up a 2024 elections...</td>\n",
       "      <td>1.596997e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Nov 27 22:39:00 +0000 2022</td>\n",
       "      <td>1.409157e+08</td>\n",
       "      <td>1.596987e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>Not important at all</td>\n",
       "      <td>0.81</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>[@MSNBC, @MaddowBlog, Setting, up, a, 2024, el...</td>\n",
       "      <td>26</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  experiment_id experiment_group  \\\n",
       "0           0              1            msnbc   \n",
       "1           1              2            msnbc   \n",
       "2           2              3            msnbc   \n",
       "\n",
       "                                                text      tweet_id  \\\n",
       "0  @MSNBC @MaddowBlog √¢¬Ä¬úSimpleton√¢¬Ä¬ôs defense√¢¬Ä¬ù...  1.596988e+18   \n",
       "1  @MSNBC @MaddowBlog I feel sorry for the sucker...  1.596993e+18   \n",
       "2  @MSNBC @MaddowBlog Setting up a 2024 elections...  1.596997e+18   \n",
       "\n",
       "   tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "0            4         0  Sun Nov 27 22:01:59 +0000 2022  1.518750e+18   \n",
       "1            0         0  Sun Nov 27 22:22:27 +0000 2022  3.202809e+09   \n",
       "2            0         0  Sun Nov 27 22:39:00 +0000 2022  1.409157e+08   \n",
       "\n",
       "   in_reply_to_status_id  ...  opinion_key                     opinion_label  \\\n",
       "0           1.596987e+18  ...            2  AGAINST student loan forgiveness   \n",
       "1           1.596987e+18  ...            1                   NEUTRAL support   \n",
       "2           1.596987e+18  ...            2  AGAINST student loan forgiveness   \n",
       "\n",
       "  opinion_annotation_confidence ego_involvement_key    ego_involvement_label  \\\n",
       "0                          0.70                   1       Somewhat important   \n",
       "1                          0.62                   3  cannot judge importance   \n",
       "2                          0.43                   2     Not important at all   \n",
       "\n",
       "   ego_involvement_annotation_confidence                 algorithm_opinion  \\\n",
       "0                                   0.95  AGAINST student loan forgiveness   \n",
       "1                                   0.65                   NEUTRAL support   \n",
       "2                                   0.81  AGAINST student loan forgiveness   \n",
       "\n",
       "                                        wordTokenize tokenLength msgLen  \n",
       "0  [@MSNBC, @MaddowBlog, √¢, ¬Ä, ¬ú, Simpleton√¢, ¬Ä, ...          47    195  \n",
       "1  [@MSNBC, @MaddowBlog, I, feel, sorry, for, the...          21    114  \n",
       "2  [@MSNBC, @MaddowBlog, Setting, up, a, 2024, el...          26    148  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# popularity--> opinion_label\n",
    "\n",
    "# create a list of our conditions\n",
    "conditions = [(fp['opinion_key'] == 0),\n",
    "    (fp['opinion_key'] == 1) ,\n",
    "    (fp['opinion_key'] == 2) ,\n",
    "    (fp['opinion_key'] == 3)]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "# values = ['supports', 'neutral', 'against', 'NA']\n",
    "values = ['FOR student loan forgiveness', 'NEUTRAL support', 'AGAINST student loan forgiveness', 'cannot judge support']\n",
    "\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "fp['algorithm_opinion'] = np.select(conditions, values)\n",
    "\n",
    "# display updated DataFrame\n",
    "fp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn df['tweet'] into token variables \n",
    "\n",
    "def tokenize_column(df): \n",
    "    '''From hw 8'''\n",
    "    # input data\n",
    "    # stem = pd.DataFrame(df)\n",
    "\n",
    "    # iterate each col's row, use a list to add it back to the dataframe\n",
    "    tokenized_list = []\n",
    "    tLenList = []\n",
    "    msgLen = []\n",
    "    for ind in df.index: \n",
    "        msg = df['text'][ind]           #tweet--> text\n",
    "        # tokens = word_tokenize(msg)\n",
    "        tokens = TweetTokenizer().tokenize(msg) # https://stackoverflow.com/questions/34714162/preventing-splitting-at-apostrophies-when-tokenizing-words-using-nltk\n",
    "        # tknzr = TweetTokenizer()\n",
    "        # tknzr.tokenize(\"@Kenichan I haven't dived many times for the ball. Man\")\n",
    "\n",
    "\n",
    "        tokenized_list.append(tokens)\n",
    "        tLenList.append(len(tokens))\n",
    "        msgLen.append(len(msg))\n",
    "\n",
    "    df['wordTokenize'] = tokenized_list\n",
    "    df['tokenLength'] = tLenList\n",
    "    df['msgLen'] = msgLen\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to remove stop words in tokenize_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_annotation_confidence</th>\n",
       "      <th>ego_involvement_key</th>\n",
       "      <th>ego_involvement_label</th>\n",
       "      <th>ego_involvement_annotation_confidence</th>\n",
       "      <th>algorithm_opinion</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>466</td>\n",
       "      <td>usedgov</td>\n",
       "      <td>@usedgov why are my student loans not transfer...</td>\n",
       "      <td>1.599892e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 22:24:29 +0000 2022</td>\n",
       "      <td>7.925171e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>0.79</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>[@usedgov, why, are, my, student, loans, not, ...</td>\n",
       "      <td>39</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>467</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Just another way of screwing the taxp...</td>\n",
       "      <td>1.599894e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 22:32:26 +0000 2022</td>\n",
       "      <td>1.518825e+18</td>\n",
       "      <td>1.599351e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>0.42</td>\n",
       "      <td>3</td>\n",
       "      <td>cannot judge importance</td>\n",
       "      <td>0.40</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>[@FoxNews, Just, another, way, of, screwing, t...</td>\n",
       "      <td>44</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>468</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews The Democrats don√¢¬Ä¬ôt seem to be tryi...</td>\n",
       "      <td>1.599904e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 23:09:08 +0000 2022</td>\n",
       "      <td>1.586128e+18</td>\n",
       "      <td>1.599901e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>cannot judge support</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>0.69</td>\n",
       "      <td>cannot judge support</td>\n",
       "      <td>[@FoxNews, The, Democrats, don√¢, ¬Ä, ¬ô, t, seem...</td>\n",
       "      <td>40</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  experiment_id experiment_group  \\\n",
       "465         465            466          usedgov   \n",
       "466         466            467          foxnews   \n",
       "467         467            468          foxnews   \n",
       "\n",
       "                                                  text      tweet_id  \\\n",
       "465  @usedgov why are my student loans not transfer...  1.599892e+18   \n",
       "466  @FoxNews Just another way of screwing the taxp...  1.599894e+18   \n",
       "467  @FoxNews The Democrats don√¢¬Ä¬ôt seem to be tryi...  1.599904e+18   \n",
       "\n",
       "     tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "465            0         0  Mon Dec 05 22:24:29 +0000 2022  7.925171e+17   \n",
       "466            0         0  Mon Dec 05 22:32:26 +0000 2022  1.518825e+18   \n",
       "467            0         0  Mon Dec 05 23:09:08 +0000 2022  1.586128e+18   \n",
       "\n",
       "     in_reply_to_status_id  ...  opinion_key  \\\n",
       "465                    NaN  ...            0   \n",
       "466           1.599351e+18  ...            2   \n",
       "467           1.599901e+18  ...            3   \n",
       "\n",
       "                        opinion_label opinion_annotation_confidence  \\\n",
       "465     FOR student loan forgiveness                           0.95   \n",
       "466  AGAINST student loan forgiveness                          0.42   \n",
       "467              cannot judge support                          0.66   \n",
       "\n",
       "    ego_involvement_key    ego_involvement_label  \\\n",
       "465                   1       Somewhat important   \n",
       "466                   3  cannot judge importance   \n",
       "467                   0           Very important   \n",
       "\n",
       "     ego_involvement_annotation_confidence                 algorithm_opinion  \\\n",
       "465                                   0.79      FOR student loan forgiveness   \n",
       "466                                   0.40  AGAINST student loan forgiveness   \n",
       "467                                   0.69              cannot judge support   \n",
       "\n",
       "                                          wordTokenize tokenLength msgLen  \n",
       "465  [@usedgov, why, are, my, student, loans, not, ...          39    183  \n",
       "466  [@FoxNews, Just, another, way, of, screwing, t...          44    244  \n",
       "467  [@FoxNews, The, Democrats, don√¢, ¬Ä, ¬ô, t, seem...          40    196  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a tokenized list from Twitter text\n",
    "df1 = tokenize_column(fp)\n",
    "df1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEUTRAL support                     193\n",
       "AGAINST student loan forgiveness    136\n",
       "FOR student loan forgiveness        120\n",
       "cannot judge support                 19\n",
       "Name: algorithm_opinion, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how balanced the data is. total count of negative, neutral, and positive sentiment. \n",
    "df1['algorithm_opinion'].value_counts() # sentiment --> algorithm_opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['wordTokenize', 'algorithm_opinion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>algorithm_opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>[@FoxNews, Just, another, way, of, screwing, t...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>[@FoxNews, The, Democrats, don√¢, ¬Ä, ¬ô, t, seem...</td>\n",
       "      <td>cannot judge support</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          wordTokenize  \\\n",
       "466  [@FoxNews, Just, another, way, of, screwing, t...   \n",
       "467  [@FoxNews, The, Democrats, don√¢, ¬Ä, ¬ô, t, seem...   \n",
       "\n",
       "                    algorithm_opinion  \n",
       "466  AGAINST student loan forgiveness  \n",
       "467              cannot judge support  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail(2)\n",
    "# fp_data = fb[['wordTokenize', 'algorithm_opinion']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def records(df): \n",
    "    # https://stackoverflow.com/questions/9758450/pandas-convert-dataframe-to-array-of-tuples\n",
    "    return df.to_records(index=False).tolist()\n",
    "df1 = records(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input need columns wordTokenize, sentiment \n",
    "word_features = get_word_features(get_words_in_tweets(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        \"\"\"word_features is predefined above as list of \n",
    "           3+ letter tokens from all tweets combined\"\"\"\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# apply features to classifier with our feature_extract function \n",
    "# it outputs a list of tuple, each tuple holds the \"feature dictionary\"\n",
    "training_set = nltk.classify.apply_features(extract_features, df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our classifier using our training data set\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGAINST student loan forgiveness'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it out \n",
    "tweet = \"@FoxNews He\\'s having issues isn't he. He can't pass a ban on pew pews, he can't do student loan forgiveness (kind of intentional btw,) he can't pass gas because his heads in the way of natural progression in his bum. He just can't catch a break man. üò™\"\n",
    "\n",
    "classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classifier to Student Loan Twitter Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>verified</th>\n",
       "      <th>user_id_char</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_annotation_confidence</th>\n",
       "      <th>ego_involvement_key</th>\n",
       "      <th>ego_involvement_label</th>\n",
       "      <th>ego_involvement_annotation_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>@MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...</td>\n",
       "      <td>1.596988e+18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Nov 27 22:01:59 +0000 2022</td>\n",
       "      <td>1.518750e+18</td>\n",
       "      <td>1.596987e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.518750e+18</td>\n",
       "      <td>183</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>@MSNBC @MaddowBlog I feel sorry for the sucker...</td>\n",
       "      <td>1.596993e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Nov 27 22:22:27 +0000 2022</td>\n",
       "      <td>3.202809e+09</td>\n",
       "      <td>1.596987e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.202809e+09</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3</td>\n",
       "      <td>cannot judge importance</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>@MSNBC @MaddowBlog Setting up a 2024 elections...</td>\n",
       "      <td>1.596997e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Nov 27 22:39:00 +0000 2022</td>\n",
       "      <td>1.409157e+08</td>\n",
       "      <td>1.596987e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.409157e+08</td>\n",
       "      <td>148</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>Not important at all</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  experiment_id experiment_group  \\\n",
       "0           0              1            msnbc   \n",
       "1           1              2            msnbc   \n",
       "2           2              3            msnbc   \n",
       "\n",
       "                                                text      tweet_id  \\\n",
       "0  @MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...  1.596988e+18   \n",
       "1  @MSNBC @MaddowBlog I feel sorry for the sucker...  1.596993e+18   \n",
       "2  @MSNBC @MaddowBlog Setting up a 2024 elections...  1.596997e+18   \n",
       "\n",
       "   tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "0            4         0  Sun Nov 27 22:01:59 +0000 2022  1.518750e+18   \n",
       "1            0         0  Sun Nov 27 22:22:27 +0000 2022  3.202809e+09   \n",
       "2            0         0  Sun Nov 27 22:39:00 +0000 2022  1.409157e+08   \n",
       "\n",
       "   in_reply_to_status_id  ...  verified  user_id_char text_length  \\\n",
       "0           1.596987e+18  ...     False  1.518750e+18         183   \n",
       "1           1.596987e+18  ...     False  3.202809e+09         114   \n",
       "2           1.596987e+18  ...     False  1.409157e+08         148   \n",
       "\n",
       "  text_word_count opinion_key                     opinion_label  \\\n",
       "0              30           2  AGAINST student loan forgiveness   \n",
       "1              20           1                   NEUTRAL support   \n",
       "2              20           2  AGAINST student loan forgiveness   \n",
       "\n",
       "  opinion_annotation_confidence  ego_involvement_key    ego_involvement_label  \\\n",
       "0                          0.70                    1       Somewhat important   \n",
       "1                          0.62                    3  cannot judge importance   \n",
       "2                          0.43                    2     Not important at all   \n",
       "\n",
       "  ego_involvement_annotation_confidence  \n",
       "0                                  0.95  \n",
       "1                                  0.65  \n",
       "2                                  0.81  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = pd.read_csv('data/master_annotated.csv')\n",
    "student_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MSNBC @MaddowBlog I feel sorry for the sucker...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@MSNBC @MaddowBlog Setting up a 2024 elections...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  @MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...   \n",
       "1  @MSNBC @MaddowBlog I feel sorry for the sucker...   \n",
       "2  @MSNBC @MaddowBlog Setting up a 2024 elections...   \n",
       "\n",
       "                          sentiment  \n",
       "0  AGAINST student loan forgiveness  \n",
       "1                   NEUTRAL support  \n",
       "2  AGAINST student loan forgiveness  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = student_data[['text', 'opinion_label']]\n",
    "test_data.columns = ['tweet', 'sentiment'] # rename so we can use tokenize_column() if needed later \n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/skpws_rj3nd2_9dzb8zqs6900000gn/T/ipykernel_83410/3321505413.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data[\"algorithm_opinion\"] = class_list\n"
     ]
    }
   ],
   "source": [
    "class_list = []\n",
    "for row in test_data.index:\n",
    "    msg = test_data['tweet'][row]\n",
    "    msg_split = msg.split()\n",
    "    result = classifier.classify(extract_features(msg_split))\n",
    "    class_list.append(result)\n",
    "test_data[\"algorithm_opinion\"] = class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/skpws_rj3nd2_9dzb8zqs6900000gn/T/ipykernel_83410/2953238877.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['match'] = np.select(conditions, values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>algorithm_opinion</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MSNBC @MaddowBlog I feel sorry for the sucker...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@MSNBC @MaddowBlog Setting up a 2024 elections...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@MSNBC @MaddowBlog If you can't pay off studen...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@MSNBC @MaddowBlog The simple defense is why s...</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>@FoxNews I don't need any bias media to tell m...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>@FoxNews He still trying to get college studen...</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>@usedgov why are my student loans not transfer...</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>@FoxNews Just another way of screwing the taxp...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>@FoxNews The Democrats don‚Äôt seem to be trying...</td>\n",
       "      <td>cannot judge support</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "0    @MSNBC @MaddowBlog ‚ÄúSimpleton‚Äôs defense‚Äù?  You...   \n",
       "1    @MSNBC @MaddowBlog I feel sorry for the sucker...   \n",
       "2    @MSNBC @MaddowBlog Setting up a 2024 elections...   \n",
       "3    @MSNBC @MaddowBlog If you can't pay off studen...   \n",
       "4    @MSNBC @MaddowBlog The simple defense is why s...   \n",
       "..                                                 ...   \n",
       "463  @FoxNews I don't need any bias media to tell m...   \n",
       "464  @FoxNews He still trying to get college studen...   \n",
       "465  @usedgov why are my student loans not transfer...   \n",
       "466  @FoxNews Just another way of screwing the taxp...   \n",
       "467  @FoxNews The Democrats don‚Äôt seem to be trying...   \n",
       "\n",
       "                            sentiment               predicted_sentiment  \\\n",
       "0    AGAINST student loan forgiveness      FOR student loan forgiveness   \n",
       "1                     NEUTRAL support                   NEUTRAL support   \n",
       "2    AGAINST student loan forgiveness                   NEUTRAL support   \n",
       "3                     NEUTRAL support                   NEUTRAL support   \n",
       "4       FOR student loan forgiveness       FOR student loan forgiveness   \n",
       "..                                ...                               ...   \n",
       "463  AGAINST student loan forgiveness  AGAINST student loan forgiveness   \n",
       "464     FOR student loan forgiveness                    NEUTRAL support   \n",
       "465     FOR student loan forgiveness       FOR student loan forgiveness   \n",
       "466  AGAINST student loan forgiveness  AGAINST student loan forgiveness   \n",
       "467              cannot judge support      FOR student loan forgiveness   \n",
       "\n",
       "                    algorithm_opinion match  \n",
       "0        FOR student loan forgiveness    no  \n",
       "1                     NEUTRAL support   yes  \n",
       "2                     NEUTRAL support    no  \n",
       "3                     NEUTRAL support   yes  \n",
       "4        FOR student loan forgiveness    no  \n",
       "..                                ...   ...  \n",
       "463  AGAINST student loan forgiveness   yes  \n",
       "464                   NEUTRAL support    no  \n",
       "465      FOR student loan forgiveness    no  \n",
       "466  AGAINST student loan forgiveness   yes  \n",
       "467      FOR student loan forgiveness    no  \n",
       "\n",
       "[468 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column to show if predicted_sentiment is the same as sentiment\n",
    "conditions = [(test_data['sentiment']==test_data['predicted_sentiment']),\n",
    "(test_data['sentiment'] != test_data['predicted_sentiment'])]\n",
    "values = ['yes', 'no']\n",
    "test_data['match'] = np.select(conditions, values)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    288\n",
       "no     180\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count up now many matches\n",
    "test_data['match'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    96\n",
       "no     67\n",
       "Name: match, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count up now many matches\n",
    "test_data['match'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 96 matches between `predicted_sentiment` and `sentiment` out of 163 test data points. That is 59% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is accurate more than 1/2 of the time. Given its constraints, 59% is acceptable. We believe that if future work address the limitations of this model, the result will improve. Below is a list of the model's limitation: \n",
    "- not able to use emoticons \n",
    "- not recognizing @username as an entity/subject\n",
    "- no treatment for commas and periods\n",
    "- treat lower/upper cases differenlty\n",
    "- special characters and hashtags are still in test data, unaddressed\n",
    "- needed to remove stop words from the training model\n",
    "- A larger training data set might yield better result. We only used 0.125% of the provided Sentiment 140 dataset (2K out of 1.6 million rows). \n",
    "\n",
    "Finally, the pre-labeled test data could not be neatly categorize. For example, when we sense \"hope\" in the text, we would label it as positive, even though there are negative sentiment that prefaces the hope/resolution. \n",
    "ex: \n",
    ">@POTUS since your student loan forgiveness move is not going to pass muster with the courts, why not do something legitimate and fair. Lock all student loans at 1% interest for all existing and future loans. #StudentLoans2022 #loanforgiveness #studentloans #college\n",
    "\n",
    "The manual we gave this tweet was 'positive' but our model categorizes it as 'negative'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@POTUS since your student loan forgiveness mov...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet sentiment  \\\n",
       "17  @POTUS since your student loan forgiveness mov...  positive   \n",
       "\n",
       "   predicted_sentiment match  \n",
       "17            negative    no  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contain_values = test_data[test_data['tweet'].str.contains('@POTUS since your student loan forgiveness move is not going to pass muster with the courts')]\n",
    "contain_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"prelim_data/training.1600000.processed.noemoticon.csv\"\n",
    "# '/Users/lnguyen/Library/CloudStorage/OneDrive-Personal/JHU/SocialMediaAnalytics_2022fall/Nguyen_Lyn_module8_hw/SocialMediaInsightsforMachineLearning.xlsm'\n",
    "\n",
    "s140_training = pd.read_csv(input_path, encoding='latin-1')\n",
    "s140_training.columns = [\"polarity\", \"tweet_id\", \"date\", \"query\", \"user\", \"tweet\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity    tweet_id                          date     query  \\\n",
       "0         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "            user                                              tweet sentiment  \n",
       "0  scotthamilton  is upset that he can't update his Facebook by ...  negative  \n",
       "1       mattycus  @Kenichan I dived many times for the ball. Man...  negative  \n",
       "2        ElleCTF    my whole body feels itchy and like its on fire   negative  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of our conditions\n",
    "conditions = [(s140_training['polarity'] == 0),\n",
    "    (s140_training['polarity'] == 2) ,\n",
    "    (s140_training['polarity'] == 4)]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['negative', 'neutral', 'positive']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "s140_training['sentiment'] = np.select(conditions, values)\n",
    "\n",
    "# display updated DataFrame\n",
    "s140_training.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the data loads in nicely. Let's reformat the training data to that of the tutorial. We need a list of tuples, where each tuple is an individual tweet. \n",
    "ex: [('text here abc', 'positive'), ('the sun is hot', 'positive'), ...]\n",
    "\n",
    "Then we need to split up the text into tokens. Differing from tutorial, we did not split words and filter those with fewer than 3 letters. Used TweetTokenizer().tokenize instead tokenize().word_tokenize to keep can't as one word and keep handle attached @."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['polarity', 'tweet_id', 'date', 'query', 'user', 'tweet', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s140_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn s140_training['tweet'] into token variables \n",
    "\n",
    "def tokenize_column(df): \n",
    "    '''From hw 8'''\n",
    "    # input data\n",
    "    # stem = pd.DataFrame(df)\n",
    "\n",
    "    # iterate each col's row, use a list to add it back to the dataframe\n",
    "    tokenized_list = []\n",
    "    tLenList = []\n",
    "    msgLen = []\n",
    "    for ind in df.index: \n",
    "        msg = df['tweet'][ind]\n",
    "        # tokens = word_tokenize(msg)\n",
    "        tokens = TweetTokenizer().tokenize(msg) # https://stackoverflow.com/questions/34714162/preventing-splitting-at-apostrophies-when-tokenizing-words-using-nltk\n",
    "        # tknzr = TweetTokenizer()\n",
    "        # tknzr.tokenize(\"@Kenichan I haven't dived many times for the ball. Man\")\n",
    "\n",
    "\n",
    "        tokenized_list.append(tokens)\n",
    "        tLenList.append(len(tokens))\n",
    "        msgLen.append(len(msg))\n",
    "\n",
    "    df['wordTokenize'] = tokenized_list\n",
    "    df['tokenLength'] = tLenList\n",
    "    df['msgLen'] = msgLen\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[is, upset, that, he, can't, update, his, Face...</td>\n",
       "      <td>24</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@Kenichan, I, dived, many, times, for, the, b...</td>\n",
       "      <td>20</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity    tweet_id                          date     query  \\\n",
       "0         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "            user                                              tweet sentiment  \\\n",
       "0  scotthamilton  is upset that he can't update his Facebook by ...  negative   \n",
       "1       mattycus  @Kenichan I dived many times for the ball. Man...  negative   \n",
       "2        ElleCTF    my whole body feels itchy and like its on fire   negative   \n",
       "\n",
       "                                        wordTokenize  tokenLength  msgLen  \n",
       "0  [is, upset, that, he, can't, update, his, Face...           24     111  \n",
       "1  [@Kenichan, I, dived, many, times, for, the, b...           20      89  \n",
       "2  [my, whole, body, feels, itchy, and, like, its...           10      47  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a tokenized list from Twitter text\n",
    "df = tokenize_column(s140_training)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    800000\n",
       "negative    799999\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how balanced the data is. total count of negative, neutral, and positive sentiment. \n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample the corpus: \n",
    "With 1.6 million rows of data, to improve run time, we will sample 2k for now and proceed with the training. We will pick 1K with positive sentiment and 1K with negative sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = df[df['sentiment'] == 'positive']\n",
    "negative_df = df[df['sentiment'] == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 799999)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get row count\n",
    "positive_df.shape[0], negative_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "positive_sample = positive_df.sample(n = 1000)\n",
    "negative_sample = negative_df.sample(n = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sample.shape[0], negative_sample.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine positive_sample & negative_sample\n",
    "sample_data = pd.concat([positive_sample, negative_sample]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>913939</th>\n",
       "      <td>[@enobytes, drank, a, 2003, I, guess, that, do...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316439</th>\n",
       "      <td>[@HellenBach, that, is, good, ,, I, wish, I, c...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498361</th>\n",
       "      <td>[@Ambee789, AGREED, &amp;, AGREED, !]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458986</th>\n",
       "      <td>[is, going, into, the, kitchen, as, the, smoke...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393378</th>\n",
       "      <td>[Scotland, has, a, ', poonia, ', playing, for,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495237</th>\n",
       "      <td>[my, toe, hurts, .]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351190</th>\n",
       "      <td>[Gotta, wait, for, 3, and, half, hours, for, m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519703</th>\n",
       "      <td>[I, feel, horrible, ., Pato, is, taking, Kat, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517241</th>\n",
       "      <td>[sitting, sick, at, home, .]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90271</th>\n",
       "      <td>[Oh, Arsenal, NOT, again, fs, (, Could, Drogba...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              wordTokenize sentiment\n",
       "913939   [@enobytes, drank, a, 2003, I, guess, that, do...  positive\n",
       "1316439  [@HellenBach, that, is, good, ,, I, wish, I, c...  positive\n",
       "1498361                  [@Ambee789, AGREED, &, AGREED, !]  positive\n",
       "1458986  [is, going, into, the, kitchen, as, the, smoke...  positive\n",
       "1393378  [Scotland, has, a, ', poonia, ', playing, for,...  positive\n",
       "...                                                    ...       ...\n",
       "495237                                 [my, toe, hurts, .]  negative\n",
       "351190   [Gotta, wait, for, 3, and, half, hours, for, m...  negative\n",
       "519703   [I, feel, horrible, ., Pato, is, taking, Kat, ...  negative\n",
       "517241                        [sitting, sick, at, home, .]  negative\n",
       "90271    [Oh, Arsenal, NOT, again, fs, (, Could, Drogba...  negative\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.concat([positive_sample, negative_sample])[['wordTokenize', 'sentiment']]\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517241</th>\n",
       "      <td>[sitting, sick, at, home, .]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90271</th>\n",
       "      <td>[Oh, Arsenal, NOT, again, fs, (, Could, Drogba...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             wordTokenize sentiment\n",
       "517241                       [sitting, sick, at, home, .]  negative\n",
       "90271   [Oh, Arsenal, NOT, again, fs, (, Could, Drogba...  negative"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.tail(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def records(df): \n",
    "    # https://stackoverflow.com/questions/9758450/pandas-convert-dataframe-to-array-of-tuples\n",
    "    return df.to_records(index=False).tolist()\n",
    "sample_data = records(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>913939</th>\n",
       "      <td>[@enobytes, drank, a, 2003, I, guess, that, do...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316439</th>\n",
       "      <td>[@HellenBach, that, is, good, ,, I, wish, I, c...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498361</th>\n",
       "      <td>[@Ambee789, AGREED, &amp;, AGREED, !]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458986</th>\n",
       "      <td>[is, going, into, the, kitchen, as, the, smoke...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393378</th>\n",
       "      <td>[Scotland, has, a, ', poonia, ', playing, for,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495237</th>\n",
       "      <td>[my, toe, hurts, .]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351190</th>\n",
       "      <td>[Gotta, wait, for, 3, and, half, hours, for, m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519703</th>\n",
       "      <td>[I, feel, horrible, ., Pato, is, taking, Kat, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517241</th>\n",
       "      <td>[sitting, sick, at, home, .]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90271</th>\n",
       "      <td>[Oh, Arsenal, NOT, again, fs, (, Could, Drogba...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              wordTokenize sentiment\n",
       "913939   [@enobytes, drank, a, 2003, I, guess, that, do...  positive\n",
       "1316439  [@HellenBach, that, is, good, ,, I, wish, I, c...  positive\n",
       "1498361                  [@Ambee789, AGREED, &, AGREED, !]  positive\n",
       "1458986  [is, going, into, the, kitchen, as, the, smoke...  positive\n",
       "1393378  [Scotland, has, a, ', poonia, ', playing, for,...  positive\n",
       "...                                                    ...       ...\n",
       "495237                                 [my, toe, hurts, .]  negative\n",
       "351190   [Gotta, wait, for, 3, and, half, hours, for, m...  negative\n",
       "519703   [I, feel, horrible, ., Pato, is, taking, Kat, ...  negative\n",
       "517241                        [sitting, sick, at, home, .]  negative\n",
       "90271    [Oh, Arsenal, NOT, again, fs, (, Could, Drogba...  negative\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb Cell 61'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000032?line=0'>1</a>\u001b[0m word_features \u001b[39m=\u001b[39m get_word_features(get_words_in_tweets(sample_data))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000032?line=1'>2</a>\u001b[0m word_features\n",
      "\u001b[1;32m/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb Cell 6'\u001b[0m in \u001b[0;36mget_words_in_tweets\u001b[0;34m(tweets)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"smush all the words in the tweets into a single list\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000005?line=5'>6</a>\u001b[0m all_words \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000005?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m (words, sentiment) \u001b[39min\u001b[39;00m tweets:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000005?line=7'>8</a>\u001b[0m   all_words\u001b[39m.\u001b[39mextend(words)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000005?line=8'>9</a>\u001b[0m \u001b[39mreturn\u001b[39;00m all_words\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(sample_data))\n",
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        \"\"\"word_features is predefined above as list of \n",
    "           3+ letter tokens from all tweets combined\"\"\"\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# apply features to classifier with our feature_extract function \n",
    "# it outputs a list of tuple, each tuple holds the \"feature dictionary\"\n",
    "training_set = nltk.classify.apply_features(extract_features, sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our classifier using our training data set\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it out \n",
    "tweet = 'we are happy with the outcome'\n",
    "classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classifier to Student Loan Twitter Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = pd.read_csv('data/master_annotated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = student_data[['tweetFullText', 'sentiment']]\n",
    "test_data.columns = ['tweet', 'sentiment'] # rename so we can use tokenize_column() if needed later \n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classifier to Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('student_sample_4hashtag_900_mod10use.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ÄúWho in the hell do they think that they are?‚Äù...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"It makes me so angry. They just continue to s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AdamParkhomenko BREAKING: I AM NOT GETTING $5...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0  ‚ÄúWho in the hell do they think that they are?‚Äù...  negative\n",
       "1  \"It makes me so angry. They just continue to s...  negative\n",
       "2  @AdamParkhomenko BREAKING: I AM NOT GETTING $5...  negative"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data= test_data[['tweetFullText', 'sentiment']]\n",
    "test_data.columns = ['tweet', 'sentiment'] # rename so we can use tokenize_column() if needed later \n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = []\n",
    "for row in test_data.index:\n",
    "    msg = test_data['tweet'][row]\n",
    "    msg_split = msg.split()\n",
    "    result = classifier.classify(extract_features(msg_split))\n",
    "    class_list.append(result)\n",
    "test_data[\"predicted_sentiment\"] = class_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ÄúWho in the hell do they think that they are?‚Äù...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"It makes me so angry. They just continue to s...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AdamParkhomenko BREAKING: I AM NOT GETTING $5...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@cnnbrk As someone who will still owe tens of ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@DrMarkScience Why should I still be paying fo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Without offering any thing close to a suggesti...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Yay for those of us with student loans held by...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>You can and still should apply for One-Time St...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>üá∫üá∏üåç #DemsAbroad writes to @usedgov @FAFSA abou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>üì£Shout it loud! Over 22 Million qualifying #st...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet sentiment  \\\n",
       "0    ‚ÄúWho in the hell do they think that they are?‚Äù...  negative   \n",
       "1    \"It makes me so angry. They just continue to s...  negative   \n",
       "2    @AdamParkhomenko BREAKING: I AM NOT GETTING $5...  negative   \n",
       "3    @cnnbrk As someone who will still owe tens of ...  negative   \n",
       "4    @DrMarkScience Why should I still be paying fo...  negative   \n",
       "..                                                 ...       ...   \n",
       "158  Without offering any thing close to a suggesti...  negative   \n",
       "159  Yay for those of us with student loans held by...  negative   \n",
       "160  You can and still should apply for One-Time St...  positive   \n",
       "161  üá∫üá∏üåç #DemsAbroad writes to @usedgov @FAFSA abou...  negative   \n",
       "162  üì£Shout it loud! Over 22 Million qualifying #st...  positive   \n",
       "\n",
       "    predicted_sentiment match  \n",
       "0              negative   yes  \n",
       "1              positive    no  \n",
       "2              positive    no  \n",
       "3              negative   yes  \n",
       "4              negative   yes  \n",
       "..                  ...   ...  \n",
       "158            positive    no  \n",
       "159            negative   yes  \n",
       "160            positive   yes  \n",
       "161            negative   yes  \n",
       "162            positive   yes  \n",
       "\n",
       "[163 rows x 4 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column to show if predicted_sentiment is the same as sentiment\n",
    "conditions = [(test_data['sentiment']==test_data['predicted_sentiment']),\n",
    "(test_data['sentiment'] != test_data['predicted_sentiment'])]\n",
    "values = ['yes', 'no']\n",
    "test_data['match'] = np.select(conditions, values)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    96\n",
       "no     67\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count up now many matches\n",
    "test_data['match'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 96 matches between `predicted_sentiment` and `sentiment` out of 163 test data points. That is 59% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is accurate more than 1/2 of the time. Given its constraints, 59% is acceptable. We believe that if future work address the limitations of this model, the result will improve. Below is a list of the model's limitation: \n",
    "- not able to use emoticons \n",
    "- not recognizing @username as an entity/subject\n",
    "- no treatment for commas and periods\n",
    "- treat lower/upper cases differenlty\n",
    "- special characters and hashtags are still in test data, unaddressed\n",
    "- needed to remove stop words from the training model\n",
    "- A larger training data set might yield better result. We only used 0.125% of the provided Sentiment 140 dataset (2K out of 1.6 million rows). \n",
    "\n",
    "Finally, the pre-labeled test data could not be neatly categorize. For example, when we sense \"hope\" in the text, we would label it as positive, even though there are negative sentiment that prefaces the hope/resolution. \n",
    "ex: \n",
    ">@POTUS since your student loan forgiveness move is not going to pass muster with the courts, why not do something legitimate and fair. Lock all student loans at 1% interest for all existing and future loans. #StudentLoans2022 #loanforgiveness #studentloans #college\n",
    "\n",
    "The manual we gave this tweet was 'positive' but our model categorizes it as 'negative'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@POTUS since your student loan forgiveness mov...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet sentiment  \\\n",
       "17  @POTUS since your student loan forgiveness mov...  positive   \n",
       "\n",
       "   predicted_sentiment match  \n",
       "17            negative    no  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contain_values = test_data[test_data['tweet'].str.contains('@POTUS since your student loan forgiveness move is not going to pass muster with the courts')]\n",
    "contain_values"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f77f65dbbcf4e8b4a8cd70b43e47feb633efa338cacdb2d15ff3e58ba7027a78"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('socialmedia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
