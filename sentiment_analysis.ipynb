{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 10 Assignment \n",
    "\n",
    "Lyn Nguyen Nov. 2022\n",
    "\n",
    "Design a sentiment analysis classifier using the **Sentiment 140** corpus and **NLTK**. Test the classifier using content from Twitter and Reddit. Describe any limitations of your sentiment analyzer. Turn in Python code as a Jupyter for the classifier.\n",
    "\n",
    "\n",
    "http://help.sentiment140.com/for-students\n",
    "\n",
    "- data: trainingandtestdata folder \n",
    "\t\n",
    "http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\n",
    "\n",
    "- how to put together a sentiment analysis classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFIER\n",
    "We get a list of features (words) and their frequencies next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIER\n",
    "import nltk\n",
    "\n",
    "def get_words_in_tweets(tweets):  \n",
    "    \"\"\"smush all the words in the tweets into a single list\"\"\"\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "      all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    \"\"\" Outputs dictionary, although \n",
    "        no frequency count shows up (wordlist)\"\"\"\n",
    "    wordlist = nltk.FreqDist(wordlist)  # FreqDist({'word1': 3, 'word2': 1, etc.}) ordered from most freq to least\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features \n",
    "\n",
    "# word_features = get_word_features(get_words_in_tweets(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        \"\"\"word_features is predefined above as list of \n",
    "           3+ letter tokens from all tweets combined\"\"\"\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL PROJECT TRIAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP WORDS - from topic_modeling_11\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.',  ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}','year', # remove it if you need punctuation\n",
    "'#', '://', '/', 'www', '-', 'com', '=', '...', 'org', 'https', '@', '&', \"'\", '\"']) # added for this assignment\n",
    "\n",
    "\n",
    "# # media stopwords only \n",
    "# stop_words = set(['msnbc', 'foxnews', 'npr', 'nytimes', 'cnn', 'usedgov', '@msnbc', '@foxnews', '@npr', '@nytimes', '@cnn', '@usedgov'])\n",
    "# stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn df['tweet'] into token variables \n",
    "\n",
    "def tokenize_column(df): \n",
    "    '''From hw 8'''\n",
    "    # input data\n",
    "    # stem = pd.DataFrame(df)\n",
    "\n",
    "    # iterate each col's row, use a list to add it back to the dataframe\n",
    "    tokenized_list = []\n",
    "    tLenList = []\n",
    "    msgLen = []\n",
    "    for ind in df.index: \n",
    "        msg = df['text'][ind]           #tweet--> text\n",
    "        # tokens = word_tokenize(msg)\n",
    "        tokens = TweetTokenizer().tokenize(msg) # https://stackoverflow.com/questions/34714162/preventing-splitting-at-apostrophies-when-tokenizing-words-using-nltk\n",
    "        # tknzr = TweetTokenizer()\n",
    "        # tknzr.tokenize(\"@Kenichan I haven't dived many times for the ball. Man\")\n",
    "\n",
    "        # tokenized_list.append(tokens) <-- uncomment for non-stopwords token\n",
    "        # tLenList.append(len(tokens))\n",
    "        # msgLen.append(len(msg))\n",
    "\n",
    "        # remove stopwords \n",
    "        # print(tokens) # <--- take out later \n",
    "        ts = [i.lower() for i in tokens if i.lower() not in stop_words]\n",
    "        # print(ts)  # <---- take out later \n",
    "        tokenized_list.append(ts)\n",
    "        tLenList.append(len(ts))\n",
    "        msgLen.append(len(ts))\n",
    "\n",
    "    df['wordTokenize'] = tokenized_list\n",
    "    df['tokenLength'] = tLenList\n",
    "    df['msgLen'] = msgLen\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@msnbc', '@maddowblog', 'â', '\\x80', '\\x9c', 'simpletonâ', '\\x80', '\\x99', 's', 'defenseâ', '\\x80', '\\x9d', '?', 'you', 'mean', 'convincing', 'voters', 'that', 'hardworking', 'tax', 'payers', 'shouldnâ', '\\x80', '\\x99', 't', 'have', 'to', 'pay', 'off', 'someone', 'elseâ', '\\x80', '\\x99', 's', 'student', 'loan', '?', 'not', 'to', 'mention', ',', 'itâ', '\\x80', '\\x99', 's', 'illegal', '.']\n",
      "------TAKE OUT STOP WORDS: ----------\n",
      "['@msnbc', '@maddowblog', 'â', '\\x80', '\\x9c', 'simpletonâ', '\\x80', '\\x99', 'defenseâ', '\\x80', '\\x9d', 'mean', 'convincing', 'voters', 'hardworking', 'tax', 'payers', 'shouldnâ', '\\x80', '\\x99', 'pay', 'someone', 'elseâ', '\\x80', '\\x99', 'student', 'loan', 'mention', 'itâ', '\\x80', '\\x99', 'illegal']\n",
      "['@msnbc', '@maddowblog', 'i', 'feel', 'sorry', 'for', 'the', 'suckers', 'who', 'fell', 'for', 'this', 'student', 'loan', 'forgiveness', 'scam', 'and', 'voted', 'for', 'joe', '.']\n",
      "------TAKE OUT STOP WORDS: ----------\n",
      "['@msnbc', '@maddowblog', 'feel', 'sorry', 'suckers', 'fell', 'student', 'loan', 'forgiveness', 'scam', 'voted', 'joe']\n",
      "['@msnbc', '@maddowblog', 'setting', 'up', 'a', '2024', 'elections', 'tsunami', 'against', 'republicans', 'on', ':', 'climate', ';', 'mass', 'shootings', ';', 'abortion', ';', 'and', 'now', ',', 'student', 'debt', 'forgiveness', '.']\n",
      "------TAKE OUT STOP WORDS: ----------\n",
      "['@msnbc', '@maddowblog', 'setting', '2024', 'elections', 'tsunami', 'republicans', 'climate', 'mass', 'shootings', 'abortion', 'student', 'debt', 'forgiveness']\n"
     ]
    }
   ],
   "source": [
    "# testout_token = tokenize_column(fp.head(3)) #<--- RUN ME\n",
    "# testout_token\n",
    "\n",
    "# remove stop words \n",
    "\n",
    "for row in testout_token.index:\n",
    "    tokened_text = testout_token['wordTokenize'][row]\n",
    "    print(tokened_text)\n",
    "    # ts = [i.lower() for i in tokens if i.lower not in stop_words]\n",
    "    print(\"------TAKE OUT STOP WORDS: ----------\")\n",
    "    ts = [i.lower() for i in tokened_text if i.lower() not in stop_words]\n",
    "\n",
    "    print(ts)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/master_annotated_2.csv\"\n",
    "fp = pd.read_csv(input_path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>user_id_char</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_key.1</th>\n",
       "      <th>opinion_label.1</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>466</td>\n",
       "      <td>usedgov</td>\n",
       "      <td>@usedgov why are my student loans not transfer...</td>\n",
       "      <td>1.599892e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 22:24:29 +0000 2022</td>\n",
       "      <td>7.925171e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.925171e+17</td>\n",
       "      <td>181</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@usedgov, student, loans, transferring, nelne...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>467</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Just another way of screwing the taxp...</td>\n",
       "      <td>1.599894e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 22:32:26 +0000 2022</td>\n",
       "      <td>1.518825e+18</td>\n",
       "      <td>1.599351e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.518825e+18</td>\n",
       "      <td>244</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, another, way, screwing, taxpayers, ...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>468</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews The Democrats donât seem to be tryi...</td>\n",
       "      <td>1.599904e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Dec 05 23:09:08 +0000 2022</td>\n",
       "      <td>1.586128e+18</td>\n",
       "      <td>1.599901e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586128e+18</td>\n",
       "      <td>194</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, democrats, donâ, , , seem, trying...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  experiment_id experiment_group  \\\n",
       "465         465            466          usedgov   \n",
       "466         466            467          foxnews   \n",
       "467         467            468          foxnews   \n",
       "\n",
       "                                                  text      tweet_id  \\\n",
       "465  @usedgov why are my student loans not transfer...  1.599892e+18   \n",
       "466  @FoxNews Just another way of screwing the taxp...  1.599894e+18   \n",
       "467  @FoxNews The Democrats donât seem to be tryi...  1.599904e+18   \n",
       "\n",
       "     tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "465            0         0  Mon Dec 05 22:24:29 +0000 2022  7.925171e+17   \n",
       "466            0         0  Mon Dec 05 22:32:26 +0000 2022  1.518825e+18   \n",
       "467            0         0  Mon Dec 05 23:09:08 +0000 2022  1.586128e+18   \n",
       "\n",
       "     in_reply_to_status_id  ...  user_id_char text_length text_word_count  \\\n",
       "465                    NaN  ...  7.925171e+17         181              33   \n",
       "466           1.599351e+18  ...  1.518825e+18         244              45   \n",
       "467           1.599901e+18  ...  1.586128e+18         194              35   \n",
       "\n",
       "    opinion_key    opinion_label  opinion_key.1     opinion_label.1  \\\n",
       "465           1  NEUTRAL support              0      Very important   \n",
       "466           1  NEUTRAL support              1  Somewhat important   \n",
       "467           1  NEUTRAL support              1  Somewhat important   \n",
       "\n",
       "                                          wordTokenize tokenLength msgLen  \n",
       "465  [@usedgov, student, loans, transferring, nelne...          21     21  \n",
       "466  [@foxnews, another, way, screwing, taxpayers, ...          20     20  \n",
       "467  [@foxnews, democrats, donâ, , , seem, trying...          26     26  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a tokenized list from Twitter text\n",
    "df1 = tokenize_column(fp)\n",
    "df1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEUTRAL support                     213\n",
       "FOR student loan forgiveness        123\n",
       "AGAINST student loan forgiveness    110\n",
       "cannot judge support                 22\n",
       "Name: opinion_label, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how balanced the data is. total count of negative, neutral, and positive sentiment. \n",
    "df1['opinion_label'].value_counts() # sentiment --> opinion_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['wordTokenize', 'opinion_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>opinion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>[@foxnews, another, way, screwing, taxpayers, ...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>[@foxnews, democrats, donâ, , , seem, trying...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          wordTokenize    opinion_label\n",
       "466  [@foxnews, another, way, screwing, taxpayers, ...  NEUTRAL support\n",
       "467  [@foxnews, democrats, donâ, , , seem, trying...  NEUTRAL support"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail(2)\n",
    "# fp_data = fb[['wordTokenize', 'opinion_label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1033)\n",
    "\n",
    "# https://www.geeksforgeeks.org/how-to-do-train-test-split-using-sklearn-in-python/\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1.get('wordTokenize')\n",
    "y = df1.get('opinion_label')\n",
    "\n",
    "# random_state previously used: 1002\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 102, test_size = .2, shuffle = True)\n",
    "\n",
    "training_data = pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def records(df): \n",
    "    # https://stackoverflow.com/questions/9758450/pandas-convert-dataframe-to-array-of-tuples\n",
    "    return df.to_records(index=False).tolist()\n",
    "training_data = records(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input need columns wordTokenize, sentiment \n",
    "word_features = get_word_features(get_words_in_tweets(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        \"\"\"word_features is predefined above as list of \n",
    "           3+ letter tokens from all tweets combined\"\"\"\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# apply features to classifier with our feature_extract function \n",
    "# it outputs a list of tuple, each tuple holds the \"feature dictionary\"\n",
    "training_set = nltk.classify.apply_features(extract_features, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our classifier using our training data set\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL support'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it out \n",
    "tweet = \"@FoxNews Stop Federal Funding and student loans to attend these schools.\"\n",
    "\n",
    "classifier.classify(extract_features(tweet.split()))  # did not take in stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply classifier to Student Loan Twitter Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>opinion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>[@foxnews, hoping, dream, lasts, long, enough,...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>[@foxnews, yep, record, high, gas, prices, bor...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[@foxnews, everybody, already, paid, student, ...</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>[@foxnews, like, student, loan, forgiveness, p...</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          wordTokenize  \\\n",
       "129  [@foxnews, hoping, dream, lasts, long, enough,...   \n",
       "441  [@foxnews, yep, record, high, gas, prices, bor...   \n",
       "59   [@foxnews, everybody, already, paid, student, ...   \n",
       "324  [@foxnews, like, student, loan, forgiveness, p...   \n",
       "\n",
       "                        opinion_label  \n",
       "129                   NEUTRAL support  \n",
       "441                   NEUTRAL support  \n",
       "59   AGAINST student loan forgiveness  \n",
       "324                   NEUTRAL support  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data \n",
    "test_data = pd.concat([X_test, y_test], axis = 1)\n",
    "test_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of test data \n",
    "test_index = X_test.index\n",
    "test_index\n",
    "# grab full dataset using test data index and make it \"test_data\"\n",
    "test_data = fp.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>user_id_char</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_key.1</th>\n",
       "      <th>opinion_label.1</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews He is hoping his dream lasts long eno...</td>\n",
       "      <td>1.598376e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 17:59:36 +0000 2022</td>\n",
       "      <td>1.384685e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384685e+18</td>\n",
       "      <td>210</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, hoping, dream, lasts, long, enough,...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>442</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Yep a record in high gas prices borde...</td>\n",
       "      <td>1.599518e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 04 21:36:55 +0000 2022</td>\n",
       "      <td>8.447381e+17</td>\n",
       "      <td>1.599461e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>8.447381e+17</td>\n",
       "      <td>288</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, yep, record, high, gas, prices, bor...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews So everybody that has already paid th...</td>\n",
       "      <td>1.598302e+18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 13:04:54 +0000 2022</td>\n",
       "      <td>1.586865e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586865e+18</td>\n",
       "      <td>99</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, everybody, already, paid, student, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>325</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews This is like student loan forgiveness...</td>\n",
       "      <td>1.599111e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 03 18:39:07 +0000 2022</td>\n",
       "      <td>1.549778e+18</td>\n",
       "      <td>1.599109e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.549778e+18</td>\n",
       "      <td>118</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, like, student, loan, forgiveness, p...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Student debt is a national crisis. It...</td>\n",
       "      <td>1.598325e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 14:33:58 +0000 2022</td>\n",
       "      <td>1.589460e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589460e+18</td>\n",
       "      <td>278</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, student, debt, national, crisis, ea...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>411</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Looks like we have a new  âweâre ...</td>\n",
       "      <td>1.599384e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 04 12:44:52 +0000 2022</td>\n",
       "      <td>1.570620e+18</td>\n",
       "      <td>1.599351e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.570620e+18</td>\n",
       "      <td>183</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, looks, like, new, â, , , weâ, , ...</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>331</td>\n",
       "      <td>332</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Ah yes, the good old switch-a-roo to ...</td>\n",
       "      <td>1.599119e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 03 19:12:15 +0000 2022</td>\n",
       "      <td>1.330691e+18</td>\n",
       "      <td>1.599109e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.330691e+18</td>\n",
       "      <td>258</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, ah, yes, good, old, switch-a-roo, b...</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews If Biden really wants to help ALL Ame...</td>\n",
       "      <td>1.598320e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 14:16:52 +0000 2022</td>\n",
       "      <td>1.586148e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586148e+18</td>\n",
       "      <td>157</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, biden, really, wants, help, america...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>409</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews If CA wants to do this with their mon...</td>\n",
       "      <td>1.599383e+18</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 04 12:39:55 +0000 2022</td>\n",
       "      <td>1.585820e+18</td>\n",
       "      <td>1.599351e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.585820e+18</td>\n",
       "      <td>277</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, ca, wants, money, rest, country, le...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>200</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews I'm for student loan debt relief. If ...</td>\n",
       "      <td>1.598490e+18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Dec 02 01:30:00 +0000 2022</td>\n",
       "      <td>1.545391e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.545391e+18</td>\n",
       "      <td>160</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, i'm, student, loan, debt, relief, b...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  experiment_id experiment_group  \\\n",
       "129         129            130          foxnews   \n",
       "441         441            442          foxnews   \n",
       "59           59             60          foxnews   \n",
       "324         324            325          foxnews   \n",
       "86           86             87          foxnews   \n",
       "..          ...            ...              ...   \n",
       "410         410            411          foxnews   \n",
       "331         331            332          foxnews   \n",
       "82           82             83          foxnews   \n",
       "408         408            409          foxnews   \n",
       "199         199            200          foxnews   \n",
       "\n",
       "                                                  text      tweet_id  \\\n",
       "129  @FoxNews He is hoping his dream lasts long eno...  1.598376e+18   \n",
       "441  @FoxNews Yep a record in high gas prices borde...  1.599518e+18   \n",
       "59   @FoxNews So everybody that has already paid th...  1.598302e+18   \n",
       "324  @FoxNews This is like student loan forgiveness...  1.599111e+18   \n",
       "86   @FoxNews Student debt is a national crisis. It...  1.598325e+18   \n",
       "..                                                 ...           ...   \n",
       "410  @FoxNews Looks like we have a new  âweâre ...  1.599384e+18   \n",
       "331  @FoxNews Ah yes, the good old switch-a-roo to ...  1.599119e+18   \n",
       "82   @FoxNews If Biden really wants to help ALL Ame...  1.598320e+18   \n",
       "408  @FoxNews If CA wants to do this with their mon...  1.599383e+18   \n",
       "199  @FoxNews I'm for student loan debt relief. If ...  1.598490e+18   \n",
       "\n",
       "     tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "129            0         0  Thu Dec 01 17:59:36 +0000 2022  1.384685e+18   \n",
       "441            0         0  Sun Dec 04 21:36:55 +0000 2022  8.447381e+17   \n",
       "59             4         0  Thu Dec 01 13:04:54 +0000 2022  1.586865e+18   \n",
       "324            0         0  Sat Dec 03 18:39:07 +0000 2022  1.549778e+18   \n",
       "86             0         0  Thu Dec 01 14:33:58 +0000 2022  1.589460e+18   \n",
       "..           ...       ...                             ...           ...   \n",
       "410            0         0  Sun Dec 04 12:44:52 +0000 2022  1.570620e+18   \n",
       "331            0         0  Sat Dec 03 19:12:15 +0000 2022  1.330691e+18   \n",
       "82             0         0  Thu Dec 01 14:16:52 +0000 2022  1.586148e+18   \n",
       "408            5         0  Sun Dec 04 12:39:55 +0000 2022  1.585820e+18   \n",
       "199            2         0  Fri Dec 02 01:30:00 +0000 2022  1.545391e+18   \n",
       "\n",
       "     in_reply_to_status_id  ...  user_id_char text_length text_word_count  \\\n",
       "129           1.598271e+18  ...  1.384685e+18         210              41   \n",
       "441           1.599461e+18  ...  8.447381e+17         288              42   \n",
       "59            1.598271e+18  ...  1.586865e+18          99              17   \n",
       "324           1.599109e+18  ...  1.549778e+18         118              18   \n",
       "86            1.598271e+18  ...  1.589460e+18         278              54   \n",
       "..                     ...  ...           ...         ...             ...   \n",
       "410           1.599351e+18  ...  1.570620e+18         183              34   \n",
       "331           1.599109e+18  ...  1.330691e+18         258              47   \n",
       "82            1.598271e+18  ...  1.586148e+18         157              28   \n",
       "408           1.599351e+18  ...  1.585820e+18         277              56   \n",
       "199           1.598271e+18  ...  1.545391e+18         160              27   \n",
       "\n",
       "    opinion_key                     opinion_label  opinion_key.1  \\\n",
       "129           1                   NEUTRAL support              1   \n",
       "441           1                   NEUTRAL support              0   \n",
       "59            2  AGAINST student loan forgiveness              1   \n",
       "324           1                   NEUTRAL support              0   \n",
       "86            1                   NEUTRAL support              1   \n",
       "..          ...                               ...            ...   \n",
       "410           0      FOR student loan forgiveness              0   \n",
       "331           0      FOR student loan forgiveness              0   \n",
       "82            0      FOR student loan forgiveness              0   \n",
       "408           1                   NEUTRAL support              1   \n",
       "199           0      FOR student loan forgiveness              1   \n",
       "\n",
       "        opinion_label.1                                       wordTokenize  \\\n",
       "129  Somewhat important  [@foxnews, hoping, dream, lasts, long, enough,...   \n",
       "441      Very important  [@foxnews, yep, record, high, gas, prices, bor...   \n",
       "59   Somewhat important  [@foxnews, everybody, already, paid, student, ...   \n",
       "324      Very important  [@foxnews, like, student, loan, forgiveness, p...   \n",
       "86   Somewhat important  [@foxnews, student, debt, national, crisis, ea...   \n",
       "..                  ...                                                ...   \n",
       "410      Very important  [@foxnews, looks, like, new, â, , , weâ, , ...   \n",
       "331      Very important  [@foxnews, ah, yes, good, old, switch-a-roo, b...   \n",
       "82       Very important  [@foxnews, biden, really, wants, help, america...   \n",
       "408  Somewhat important  [@foxnews, ca, wants, money, rest, country, le...   \n",
       "199  Somewhat important  [@foxnews, i'm, student, loan, debt, relief, b...   \n",
       "\n",
       "    tokenLength msgLen  \n",
       "129          26     26  \n",
       "441          30     30  \n",
       "59            9      9  \n",
       "324          14     14  \n",
       "86           29     29  \n",
       "..          ...    ...  \n",
       "410          32     32  \n",
       "331          28     28  \n",
       "82           19     19  \n",
       "408          25     25  \n",
       "199          16     16  \n",
       "\n",
       "[94 rows x 36 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test_data[['text', 'opinion_label']]\n",
    "# test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>user_id_char</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_key.1</th>\n",
       "      <th>opinion_label.1</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews He is hoping his dream lasts long eno...</td>\n",
       "      <td>1.598376e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 17:59:36 +0000 2022</td>\n",
       "      <td>1.384685e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384685e+18</td>\n",
       "      <td>210</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, hoping, dream, lasts, long, enough,...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>442</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Yep a record in high gas prices borde...</td>\n",
       "      <td>1.599518e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 04 21:36:55 +0000 2022</td>\n",
       "      <td>8.447381e+17</td>\n",
       "      <td>1.599461e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>8.447381e+17</td>\n",
       "      <td>288</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, yep, record, high, gas, prices, bor...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews So everybody that has already paid th...</td>\n",
       "      <td>1.598302e+18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 13:04:54 +0000 2022</td>\n",
       "      <td>1.586865e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586865e+18</td>\n",
       "      <td>99</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, everybody, already, paid, student, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  experiment_id experiment_group  \\\n",
       "129         129            130          foxnews   \n",
       "441         441            442          foxnews   \n",
       "59           59             60          foxnews   \n",
       "\n",
       "                                                  text      tweet_id  \\\n",
       "129  @FoxNews He is hoping his dream lasts long eno...  1.598376e+18   \n",
       "441  @FoxNews Yep a record in high gas prices borde...  1.599518e+18   \n",
       "59   @FoxNews So everybody that has already paid th...  1.598302e+18   \n",
       "\n",
       "     tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "129            0         0  Thu Dec 01 17:59:36 +0000 2022  1.384685e+18   \n",
       "441            0         0  Sun Dec 04 21:36:55 +0000 2022  8.447381e+17   \n",
       "59             4         0  Thu Dec 01 13:04:54 +0000 2022  1.586865e+18   \n",
       "\n",
       "     in_reply_to_status_id  ...  user_id_char text_length text_word_count  \\\n",
       "129           1.598271e+18  ...  1.384685e+18         210              41   \n",
       "441           1.599461e+18  ...  8.447381e+17         288              42   \n",
       "59            1.598271e+18  ...  1.586865e+18          99              17   \n",
       "\n",
       "    opinion_key                     opinion_label  opinion_key.1  \\\n",
       "129           1                   NEUTRAL support              1   \n",
       "441           1                   NEUTRAL support              0   \n",
       "59            2  AGAINST student loan forgiveness              1   \n",
       "\n",
       "        opinion_label.1                                       wordTokenize  \\\n",
       "129  Somewhat important  [@foxnews, hoping, dream, lasts, long, enough,...   \n",
       "441      Very important  [@foxnews, yep, record, high, gas, prices, bor...   \n",
       "59   Somewhat important  [@foxnews, everybody, already, paid, student, ...   \n",
       "\n",
       "    tokenLength msgLen  \n",
       "129          26     26  \n",
       "441          30     30  \n",
       "59            9      9  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/skpws_rj3nd2_9dzb8zqs6900000gn/T/ipykernel_96159/2298502193.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data[\"predicted_sentiment\"] = class_list\n"
     ]
    }
   ],
   "source": [
    "# RUN TEST DATA THROUGH MODEL \n",
    "# tokenize test data first or use pre-tokenized column `wordTokenize` instead of 'text' \n",
    "    # test_data = tokenize_column(test_data) # <-- run this if new data isn't yet tokenized. will work if tweet column is named 'text'\n",
    "\n",
    "class_list = []\n",
    "for row in test_data.index:\n",
    "    # msg = test_data['text'][row]\n",
    "    msg_split = test_data['wordTokenize'][row]\n",
    "    # msg_split = msg.split()  # doesn't take into account stop words \n",
    "    result = classifier.classify(extract_features(msg_split))\n",
    "    class_list.append(result)\n",
    "test_data[\"predicted_sentiment\"] = class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_key.1</th>\n",
       "      <th>opinion_label.1</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews He is hoping his dream lasts long eno...</td>\n",
       "      <td>1.598376e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 17:59:36 +0000 2022</td>\n",
       "      <td>1.384685e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, hoping, dream, lasts, long, enough,...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>442</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Yep a record in high gas prices borde...</td>\n",
       "      <td>1.599518e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 04 21:36:55 +0000 2022</td>\n",
       "      <td>8.447381e+17</td>\n",
       "      <td>1.599461e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>288</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, yep, record, high, gas, prices, bor...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews So everybody that has already paid th...</td>\n",
       "      <td>1.598302e+18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 13:04:54 +0000 2022</td>\n",
       "      <td>1.586865e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, everybody, already, paid, student, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  experiment_id experiment_group  \\\n",
       "129         129            130          foxnews   \n",
       "441         441            442          foxnews   \n",
       "59           59             60          foxnews   \n",
       "\n",
       "                                                  text      tweet_id  \\\n",
       "129  @FoxNews He is hoping his dream lasts long eno...  1.598376e+18   \n",
       "441  @FoxNews Yep a record in high gas prices borde...  1.599518e+18   \n",
       "59   @FoxNews So everybody that has already paid th...  1.598302e+18   \n",
       "\n",
       "     tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "129            0         0  Thu Dec 01 17:59:36 +0000 2022  1.384685e+18   \n",
       "441            0         0  Sun Dec 04 21:36:55 +0000 2022  8.447381e+17   \n",
       "59             4         0  Thu Dec 01 13:04:54 +0000 2022  1.586865e+18   \n",
       "\n",
       "     in_reply_to_status_id  ...  text_length text_word_count opinion_key  \\\n",
       "129           1.598271e+18  ...          210              41           1   \n",
       "441           1.599461e+18  ...          288              42           1   \n",
       "59            1.598271e+18  ...           99              17           2   \n",
       "\n",
       "                        opinion_label opinion_key.1     opinion_label.1  \\\n",
       "129                   NEUTRAL support             1  Somewhat important   \n",
       "441                   NEUTRAL support             0      Very important   \n",
       "59   AGAINST student loan forgiveness             1  Somewhat important   \n",
       "\n",
       "                                          wordTokenize  tokenLength msgLen  \\\n",
       "129  [@foxnews, hoping, dream, lasts, long, enough,...           26     26   \n",
       "441  [@foxnews, yep, record, high, gas, prices, bor...           30     30   \n",
       "59   [@foxnews, everybody, already, paid, student, ...            9      9   \n",
       "\n",
       "                  predicted_sentiment  \n",
       "129  AGAINST student loan forgiveness  \n",
       "441                   NEUTRAL support  \n",
       "59                    NEUTRAL support  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/skpws_rj3nd2_9dzb8zqs6900000gn/T/ipykernel_96159/3574436141.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['match'] = np.select(conditions, values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>opinion_key</th>\n",
       "      <th>opinion_label</th>\n",
       "      <th>opinion_key.1</th>\n",
       "      <th>opinion_label.1</th>\n",
       "      <th>wordTokenize</th>\n",
       "      <th>tokenLength</th>\n",
       "      <th>msgLen</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews He is hoping his dream lasts long eno...</td>\n",
       "      <td>1.598376e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 17:59:36 +0000 2022</td>\n",
       "      <td>1.384685e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, hoping, dream, lasts, long, enough,...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>442</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Yep a record in high gas prices borde...</td>\n",
       "      <td>1.599518e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 04 21:36:55 +0000 2022</td>\n",
       "      <td>8.447381e+17</td>\n",
       "      <td>1.599461e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, yep, record, high, gas, prices, bor...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews So everybody that has already paid th...</td>\n",
       "      <td>1.598302e+18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 13:04:54 +0000 2022</td>\n",
       "      <td>1.586865e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, everybody, already, paid, student, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>325</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews This is like student loan forgiveness...</td>\n",
       "      <td>1.599111e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 03 18:39:07 +0000 2022</td>\n",
       "      <td>1.549778e+18</td>\n",
       "      <td>1.599109e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, like, student, loan, forgiveness, p...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>AGAINST student loan forgiveness</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Student debt is a national crisis. It...</td>\n",
       "      <td>1.598325e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 14:33:58 +0000 2022</td>\n",
       "      <td>1.589460e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, student, debt, national, crisis, ea...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>411</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Looks like we have a new  âweâre ...</td>\n",
       "      <td>1.599384e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 04 12:44:52 +0000 2022</td>\n",
       "      <td>1.570620e+18</td>\n",
       "      <td>1.599351e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, looks, like, new, â, , , weâ, , ...</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>331</td>\n",
       "      <td>332</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews Ah yes, the good old switch-a-roo to ...</td>\n",
       "      <td>1.599119e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 03 19:12:15 +0000 2022</td>\n",
       "      <td>1.330691e+18</td>\n",
       "      <td>1.599109e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, ah, yes, good, old, switch-a-roo, b...</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews If Biden really wants to help ALL Ame...</td>\n",
       "      <td>1.598320e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Dec 01 14:16:52 +0000 2022</td>\n",
       "      <td>1.586148e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>0</td>\n",
       "      <td>Very important</td>\n",
       "      <td>[@foxnews, biden, really, wants, help, america...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>409</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews If CA wants to do this with their mon...</td>\n",
       "      <td>1.599383e+18</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 04 12:39:55 +0000 2022</td>\n",
       "      <td>1.585820e+18</td>\n",
       "      <td>1.599351e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, ca, wants, money, rest, country, le...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>200</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>@FoxNews I'm for student loan debt relief. If ...</td>\n",
       "      <td>1.598490e+18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Dec 02 01:30:00 +0000 2022</td>\n",
       "      <td>1.545391e+18</td>\n",
       "      <td>1.598271e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>FOR student loan forgiveness</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat important</td>\n",
       "      <td>[@foxnews, i'm, student, loan, debt, relief, b...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NEUTRAL support</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  experiment_id experiment_group  \\\n",
       "129         129            130          foxnews   \n",
       "441         441            442          foxnews   \n",
       "59           59             60          foxnews   \n",
       "324         324            325          foxnews   \n",
       "86           86             87          foxnews   \n",
       "..          ...            ...              ...   \n",
       "410         410            411          foxnews   \n",
       "331         331            332          foxnews   \n",
       "82           82             83          foxnews   \n",
       "408         408            409          foxnews   \n",
       "199         199            200          foxnews   \n",
       "\n",
       "                                                  text      tweet_id  \\\n",
       "129  @FoxNews He is hoping his dream lasts long eno...  1.598376e+18   \n",
       "441  @FoxNews Yep a record in high gas prices borde...  1.599518e+18   \n",
       "59   @FoxNews So everybody that has already paid th...  1.598302e+18   \n",
       "324  @FoxNews This is like student loan forgiveness...  1.599111e+18   \n",
       "86   @FoxNews Student debt is a national crisis. It...  1.598325e+18   \n",
       "..                                                 ...           ...   \n",
       "410  @FoxNews Looks like we have a new  âweâre ...  1.599384e+18   \n",
       "331  @FoxNews Ah yes, the good old switch-a-roo to ...  1.599119e+18   \n",
       "82   @FoxNews If Biden really wants to help ALL Ame...  1.598320e+18   \n",
       "408  @FoxNews If CA wants to do this with their mon...  1.599383e+18   \n",
       "199  @FoxNews I'm for student loan debt relief. If ...  1.598490e+18   \n",
       "\n",
       "     tweet_likes  retweets                tweet_created_at       user_id  \\\n",
       "129            0         0  Thu Dec 01 17:59:36 +0000 2022  1.384685e+18   \n",
       "441            0         0  Sun Dec 04 21:36:55 +0000 2022  8.447381e+17   \n",
       "59             4         0  Thu Dec 01 13:04:54 +0000 2022  1.586865e+18   \n",
       "324            0         0  Sat Dec 03 18:39:07 +0000 2022  1.549778e+18   \n",
       "86             0         0  Thu Dec 01 14:33:58 +0000 2022  1.589460e+18   \n",
       "..           ...       ...                             ...           ...   \n",
       "410            0         0  Sun Dec 04 12:44:52 +0000 2022  1.570620e+18   \n",
       "331            0         0  Sat Dec 03 19:12:15 +0000 2022  1.330691e+18   \n",
       "82             0         0  Thu Dec 01 14:16:52 +0000 2022  1.586148e+18   \n",
       "408            5         0  Sun Dec 04 12:39:55 +0000 2022  1.585820e+18   \n",
       "199            2         0  Fri Dec 02 01:30:00 +0000 2022  1.545391e+18   \n",
       "\n",
       "     in_reply_to_status_id  ...  text_word_count opinion_key  \\\n",
       "129           1.598271e+18  ...               41           1   \n",
       "441           1.599461e+18  ...               42           1   \n",
       "59            1.598271e+18  ...               17           2   \n",
       "324           1.599109e+18  ...               18           1   \n",
       "86            1.598271e+18  ...               54           1   \n",
       "..                     ...  ...              ...         ...   \n",
       "410           1.599351e+18  ...               34           0   \n",
       "331           1.599109e+18  ...               47           0   \n",
       "82            1.598271e+18  ...               28           0   \n",
       "408           1.599351e+18  ...               56           1   \n",
       "199           1.598271e+18  ...               27           0   \n",
       "\n",
       "                        opinion_label opinion_key.1     opinion_label.1  \\\n",
       "129                   NEUTRAL support             1  Somewhat important   \n",
       "441                   NEUTRAL support             0      Very important   \n",
       "59   AGAINST student loan forgiveness             1  Somewhat important   \n",
       "324                   NEUTRAL support             0      Very important   \n",
       "86                    NEUTRAL support             1  Somewhat important   \n",
       "..                                ...           ...                 ...   \n",
       "410      FOR student loan forgiveness             0      Very important   \n",
       "331      FOR student loan forgiveness             0      Very important   \n",
       "82       FOR student loan forgiveness             0      Very important   \n",
       "408                   NEUTRAL support             1  Somewhat important   \n",
       "199      FOR student loan forgiveness             1  Somewhat important   \n",
       "\n",
       "                                          wordTokenize tokenLength  msgLen  \\\n",
       "129  [@foxnews, hoping, dream, lasts, long, enough,...          26      26   \n",
       "441  [@foxnews, yep, record, high, gas, prices, bor...          30      30   \n",
       "59   [@foxnews, everybody, already, paid, student, ...           9       9   \n",
       "324  [@foxnews, like, student, loan, forgiveness, p...          14      14   \n",
       "86   [@foxnews, student, debt, national, crisis, ea...          29      29   \n",
       "..                                                 ...         ...     ...   \n",
       "410  [@foxnews, looks, like, new, â, , , weâ, , ...          32      32   \n",
       "331  [@foxnews, ah, yes, good, old, switch-a-roo, b...          28      28   \n",
       "82   [@foxnews, biden, really, wants, help, america...          19      19   \n",
       "408  [@foxnews, ca, wants, money, rest, country, le...          25      25   \n",
       "199  [@foxnews, i'm, student, loan, debt, relief, b...          16      16   \n",
       "\n",
       "                  predicted_sentiment match  \n",
       "129  AGAINST student loan forgiveness    no  \n",
       "441                   NEUTRAL support   yes  \n",
       "59                    NEUTRAL support    no  \n",
       "324  AGAINST student loan forgiveness    no  \n",
       "86                    NEUTRAL support   yes  \n",
       "..                                ...   ...  \n",
       "410      FOR student loan forgiveness   yes  \n",
       "331                   NEUTRAL support    no  \n",
       "82                    NEUTRAL support    no  \n",
       "408                   NEUTRAL support   yes  \n",
       "199                   NEUTRAL support    no  \n",
       "\n",
       "[94 rows x 38 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column to show if predicted_sentiment is the same as sentiment\n",
    "conditions = [(test_data['opinion_label']==test_data['predicted_sentiment']),\n",
    "(test_data['opinion_label'] != test_data['predicted_sentiment'])]\n",
    "values = ['yes', 'no']\n",
    "test_data['match'] = np.select(conditions, values)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     60\n",
       "yes    34\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count up now many matches\n",
    "test_data['match'].value_counts() # 48/46 = 61% correct  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we calculate **recall** and **precision** of the multiclass model? \n",
    "\n",
    "- https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/\n",
    "\n",
    "- https://towardsdatascience.com/is-accuracy-everything-96da9afd540d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Creating  a confusion matrix,which compares the y_test and y_pred\n",
    "cm = confusion_matrix(test_data['opinion_label'], test_data['predicted_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOR student loan forgiveness</th>\n",
       "      <th>NEUTRAL support</th>\n",
       "      <th>AGAINST student loan forgiveness</th>\n",
       "      <th>cannot judge support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOR student loan forgiveness</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL support</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGAINST student loan forgiveness</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cannot judge support</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  FOR student loan forgiveness  \\\n",
       "FOR student loan forgiveness                                 2   \n",
       "NEUTRAL support                                              0   \n",
       "AGAINST student loan forgiveness                             6   \n",
       "cannot judge support                                         0   \n",
       "\n",
       "                                  NEUTRAL support  \\\n",
       "FOR student loan forgiveness                    9   \n",
       "NEUTRAL support                                 2   \n",
       "AGAINST student loan forgiveness                5   \n",
       "cannot judge support                            1   \n",
       "\n",
       "                                  AGAINST student loan forgiveness  \\\n",
       "FOR student loan forgiveness                                    10   \n",
       "NEUTRAL support                                                 22   \n",
       "AGAINST student loan forgiveness                                30   \n",
       "cannot judge support                                             7   \n",
       "\n",
       "                                  cannot judge support  \n",
       "FOR student loan forgiveness                         0  \n",
       "NEUTRAL support                                      0  \n",
       "AGAINST student loan forgiveness                     0  \n",
       "cannot judge support                                 0  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['FOR student loan forgiveness','NEUTRAL support','AGAINST student loan forgiveness', 'cannot judge support'], \n",
    "                     columns = ['FOR student loan forgiveness','NEUTRAL support','AGAINST student loan forgiveness', 'cannot judge support'])\n",
    "\n",
    "# actual value (row), predicted values (columns)\n",
    "cm_df\n",
    "\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDIT AFTER MODEL COMPLETED\n",
    "\n",
    "There are 96 matches between `predicted_sentiment` and `sentiment` out of 163 test data points. That is 59% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is accurate more than 1/2 of the time. Given its constraints, 59% is acceptable. We believe that if future work address the limitations of this model, the result will improve. Below is a list of the model's limitation: \n",
    "- not able to use emoticons \n",
    "- not recognizing @username as an entity/subject\n",
    "- no treatment for commas and periods\n",
    "- treat lower/upper cases differenlty\n",
    "- special characters and hashtags are still in test data, unaddressed\n",
    "- needed to remove stop words from the training model\n",
    "- A larger training data set might yield better result. We only used 0.125% of the provided Sentiment 140 dataset (2K out of 1.6 million rows). \n",
    "\n",
    "Finally, the pre-labeled test data could not be neatly categorize. For example, when we sense \"hope\" in the text, we would label it as positive, even though there are negative sentiment that prefaces the hope/resolution. \n",
    "ex: \n",
    ">@POTUS since your student loan forgiveness move is not going to pass muster with the courts, why not do something legitimate and fair. Lock all student loans at 1% interest for all existing and future loans. #StudentLoans2022 #loanforgiveness #studentloans #college\n",
    "\n",
    "The manual we gave this tweet was 'positive' but our model categorizes it as 'negative'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tweet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tweet'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb Cell 38'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000032?line=0'>1</a>\u001b[0m contain_values \u001b[39m=\u001b[39m test_data[test_data[\u001b[39m'\u001b[39;49m\u001b[39mtweet\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m'\u001b[39m\u001b[39m@POTUS since your student loan forgiveness move is not going to pass muster with the courts\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lnguyen/Documents/analysis-of-public-opinion/sentiment_analysis.ipynb#ch0000032?line=1'>2</a>\u001b[0m contain_values\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lnguyen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tweet'"
     ]
    }
   ],
   "source": [
    "contain_values = test_data[test_data['tweet'].str.contains('@POTUS since your student loan forgiveness move is not going to pass muster with the courts')]\n",
    "contain_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f77f65dbbcf4e8b4a8cd70b43e47feb633efa338cacdb2d15ff3e58ba7027a78"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('socialmedia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
